{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de0e9f61-1e75-457d-aadd-144a48eeaad6",
   "metadata": {},
   "source": [
    "# PrivECG: Anonymizing ECG Data for Privacy-Preserving Cardiovascular Diagnosis\n",
    "\n",
    "## Github Link: [https://github.com/DHUIUC/PrivECG](https://github.com/DHUIUC/PrivECG)\n",
    "\n",
    "## Authors\n",
    "- Original Authors: Alexis Nolin-Lapalme, Robert Avram, Hussin Julie\n",
    "- Contributor: Dillon Harding (Improvements, Ablations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22e014c-c87e-45dd-a6c2-18749acd55f0",
   "metadata": {},
   "source": [
    "# Introduction:\r\n",
    "## Background\n",
    "In the original paper, PrivECG aims to address the potential privacy risks associated with using electrocardiogram (ECG) data for diagnosing cardiovascular disease. ECG data is invaluable in its ability be utilized in training machine learning models, though there is the potential of the data to reveal private attributes such as age and sex. With state of the art models, even patient re-identification is possible. A potential solution to this issue is PrivECG, which aids in anonymizing the ECG data while retaining the diagnostic utility of the data. \n",
    "\n",
    "The approach used in PrivECG involves a Generative Adversarial Network (GAN) to anonymize patient data. The model aims to reduce the accuracy of predicting a patient's sex while preserving other features of the data relevant to disease diagnosis. The GAN uses a generator and discriminator to achieve this result. The discriminator attempts to determine the sex of a patient based on the ECG data, whereas the generator learns to remove features of the data that would otherwise assist in the determining of a patient's sex. This ideally makes the accuracy effectively random (~50%).\n",
    "\n",
    "The original paper cites a variant of PrivECG, \"PrivECG-lambda\", limited the sex prediction accuracy to 0.529 +- 0.014, while retaining its ability to determine diagnosis on the transformed data. The diagnosis classification for \"PrivECG-lambda\" had very high performance with an AUPR of 0.96 +- 0.006 despite limiting the ability of predicting the patient's sex. This paper is incredibly meaningful for data privacy in machine learning models, as models can utilize privECG to eliminate predictibility of identifiable traits while retaining viability of their target prediction variable. y.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f423c20-b381-4d42-8435-565c9beefe75",
   "metadata": {},
   "source": [
    "# Scope of Reproducibility:\n",
    "\n",
    "In recreating this project, I will be attempting to test two hypotheses. The paper claims that it can “anonymize a large ECG database in minutes”, which leads me to believe that this paper can be recreated with any ECG dataset. \n",
    "\n",
    "- Hypothesis 1: I will be testing if it is possible to glean similar results from the paper using alternate ECG datasets than the original used in the paper.\n",
    "- Hypothesis 2: This hypothesis comes from the authors’ GitHub, in which they state a future improvement could be to “try to induce privacy by simply varying rhythm, thus requiring less transformation and allowing better readability”.\n",
    "\n",
    "I would like to see if I can make these improvements upon their codebase, and aim to do so by modifying the GAN to discriminate and generate heartbeat rhythm in conjunction with or in place of sex-defining features. I find that Transfer Learning could be beneficial in this attempt. \n",
    "\n",
    "Given the low complexity of the model as well as the manageable size of data, I believe replication of PrivECG should be possible on my personal hardware. Additionally, an aim of the project is to be efficient on large databases, which leads me to believe it could likely be done on lesser hardware. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343fc4cb-5f56-45c5-8666-ed2c37b32871",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "Below is the associated methodology in which I attempt to recreate the privECG model. One main struggle discovered in the attempt to reproduce PrivECG is installing all necessary dependencies. The packages are very dependency specific, so it is difficult to install all packages and import them with their Python version dependencies. Beyond that, a notable issue I ran into was with the CUDA version of the torch package specified in the requirements.txt file:\n",
    "\n",
    "torch==2.0.1+cu117\n",
    "\n",
    "I am currently looking at a resolution to this group of dependencies and provide an updated requirement.txt and some documentation on any specific versioning in order to replicate PrivECG's functionality. For now, I am simply using the most recent version of each package.\n",
    "\n",
    "Another dependency that is not covered in the requirements.txt is ecgdetectors, a python package in utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9835024e-e948-46bc-b282-61c6918d1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN PRIOR TO IMPORT IF MISSING DEPENDENCIES IN PYTHON ENV\n",
    "\n",
    "# I think that ipykernels might actually have been outpaced by the requirements here...\n",
    "# I managed to get the libraries to work by running the below command in conda shell:\n",
    "\n",
    "#!pip install -r requirements.txt\n",
    "\n",
    "#!pip install py-ecg-detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ef6b3bd-e343-41d5-ba4e-2be4a85d7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS ##\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random \n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a748ef-a86d-4af2-9a99-f7b1e467731f",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "One of the hypotheses lies in the ability to replicate PrivECG on separate data. I managed to find 12-lead ECG data that was made public in a separate paper (see reference 3 in references section). There are quite a few data pre-processing steps that were needed to be performed before using the data in the GAN model below. The data originally came in shape (N, 5000, 12) which is typical for an ECG, but the data existed as separate excel files, where the model expects downsampled numpy arrays of size (N, 500, 12). Thus, it was imperative to read the data (which was incredibly memory intensive) from the Excel files to numpy arrays. Beyond this, I needed to generate R-Waves and non-R-Waves, as this is key to anonymizing the data. This process relies on finding the peaks in the ECG per lead. \n",
    "\n",
    "I may need to revise the method in which I generated the R-wave and non-R-wave data. Though, I was successfully able to generate some data that should ideally be close to what is implemented in the paper. See the file: createMasks.py in my repository for my method on doing so. After generating the R-wave and non-R-wave data, I then downsampled the ECG data, R-wave, and non-R-wave data to be of size (N, 500, 12) to conform to the expected dimensions of privECG. \n",
    "\n",
    "Lastly, I sorted the file Diagnostics.xlsx by filename and retrieved the Gender column to use as my sex vector for predictors in the GAN. All of this python code exists with the repository as: createMasks.py, downsample.py, readFromExcel.py, readDiagnostics.py. The Excel data can be found in the folder /data/ in the repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b663ea75-4cfa-420a-b8a4-9d7ab3d22ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Male: 5956\n",
      "Count of Female 4690\n"
     ]
    }
   ],
   "source": [
    "## FILE AND DATA READING ##\n",
    "\n",
    "#FILEPATHS\n",
    "data_path = 'to_model/ecg_data.npy'\n",
    "r_mask_path = 'to_model/r_wave_masks.npy'\n",
    "nr_mask_path = 'to_model/non_r_wave_masks.npy'\n",
    "sex_labels_path = 'to_model/gender_data.npy'\n",
    "out_path = 'output_folder'\n",
    "\n",
    "#FORMERLY ARGUMENTS, NOW CONSTANTS\n",
    "#cuda_device = 'cuda:0'   CANT SEEM TO GET CUDA WORKING\n",
    "learning_rate = 1e-7\n",
    "batch_size_ = 64\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.990\n",
    "loss_type = 'MSE_R'\n",
    "multiplicator = 100\n",
    "mode = 'PrivECG'\n",
    "save_every = 3\n",
    "number_epochs = 500\n",
    "utility_budget = 0.0001\n",
    "experiment_id = 'exp_1'\n",
    "\n",
    "#READ FROM FILES, ESTABLISH VARS\n",
    "# device = cuda_device  --CUDA NOT WORKING\n",
    "train_X = np.load(data_path)\n",
    "R_mask = np.load(r_mask_path)\n",
    "non_R_mask = np.load(nr_mask_path)\n",
    "y_ = np.load(sex_labels_path, allow_pickle=True)\n",
    "y_ = np.array([0 if i == 'MALE' else 1 for i in y_])\n",
    "\n",
    "# Using PrivECG\n",
    "generator = GeneratorUNet()#.to(device)\n",
    "disciminator = Discriminator()#.to(device)\n",
    "\n",
    "print(\"Count of Male:\", np.count_nonzero(y_ == 0))\n",
    "print(\"Count of Female\", np.count_nonzero(y_ == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f326dfb-08ec-44c5-9424-fd1130ff78cb",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "The model below is a GAN that stays in line with the original code from the PrivECG repository. And significant modifications will contain comments, but largely the code is the same for now. The GAN utilizes methods from the 2 helper python packages called upon in the import statements under Methodology. Ideally the model is meant to run via CUDA on a GPU, but with configuration issues I have disabled this, running the model on CPU instead for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4b1975c-f806-4c58-a816-432231135cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/167 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 12, 4], expected input[64, 500, 12] to have 12 channels, but got 500 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 67\u001b[0m\n\u001b[0;32m     61\u001b[0m gen_secret \u001b[38;5;241m=\u001b[39m gen_secret\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m#gen_secret =  gen_secret.to(device=device)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# ----------- Generator --------------\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m#get outputs of the networks\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m gen_results \u001b[38;5;241m=\u001b[39m generator(x)\n\u001b[0;32m     69\u001b[0m pred_secret \u001b[38;5;241m=\u001b[39m disciminator(gen_results)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# 'MSE','MSE_R'\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\CS 598 DLH\\Final Project\\models.py:85\u001b[0m, in \u001b[0;36mGeneratorUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 85\u001b[0m     d1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1(x)\n\u001b[0;32m     86\u001b[0m     d2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown2(d1)\n\u001b[0;32m     87\u001b[0m     d3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown3(d2)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\CS 598 DLH\\Final Project\\models.py:23\u001b[0m, in \u001b[0;36mUNetDownPath.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:303\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_conv_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, weight: Tensor, bias: Optional[Tensor]):\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                         weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                         _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    307\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 12, 4], expected input[64, 500, 12] to have 12 channels, but got 500 channels instead"
     ]
    }
   ],
   "source": [
    "## LINE 73 ONWARDS FROM run_models.py FROM ORIGINAL PrivECG GitHub ##\n",
    "d_train = DatasetTrain(train_X,y_,R_mask,non_R_mask)\n",
    "\n",
    "distortion_loss = nn.MSELoss()\n",
    "adversarial_loss = nn.BCEWithLogitsLoss()\n",
    "adversarial_loss_rf = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_loader = DataLoader(dataset=d_train, batch_size=int(batch_size_), shuffle=True)\n",
    "\n",
    "optimiser_gen = torch.optim.Adam(generator.parameters(), lr=learning_rate ,betas = (beta_1, beta_2)) \n",
    "optimiser_discr = torch.optim.Adam(disciminator.parameters(), lr=learning_rate, betas = (beta_1, beta_2)) \n",
    "num_epochs = number_epochs\n",
    "\n",
    "list_fake_acc = list()\n",
    "list_true_acc = list()\n",
    "list_generator_loss = list()\n",
    "list_distortion_loss = list()\n",
    "list_gender_loss = list()\n",
    "list_genderless_loss = list()\n",
    "list_true_data_loss = list()\n",
    "list_dicriminator_loss = list()\n",
    "\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "for epochs in range(0,num_epochs):\n",
    "    print('Epoch: {}'.format(epochs))\n",
    "    G_distortion_loss_accum = 0\n",
    "    G_adversary_loss_accum = 0\n",
    "    D_real_loss_accum = 0\n",
    "    D_fake_loss_accum = 0\n",
    "\n",
    "    generator.train()\n",
    "    disciminator.train()\n",
    "    \n",
    "    acc_true_acc = list()\n",
    "    acc_fake_acc = list()\n",
    "    acc_generator_loss = list()\n",
    "    acc_distortion_loss = list()\n",
    "    acc_gender_loss = list()\n",
    "    acc_genderless_loss = list()\n",
    "    acc_true_data_loss = list()\n",
    "    acc_dicriminator_loss = list()\n",
    "\n",
    "    #LongTensor = torch.cuda.LongTensor\n",
    "    #FloatTensor = torch.cuda.FloatTensor\n",
    "\n",
    "    for i, (x, gender, r_masked, non_r_masked) in enumerate(tqdm(train_loader)):\n",
    "        gender = gender.type(torch.float32)\n",
    "        #gender =  gender.to(device=device)\n",
    "        #x = x.to(device=device, dtype=torch.float32)\n",
    "\n",
    "        #non_r_masked =  non_r_masked.to(device,dtype=torch.float32)\n",
    "        #r_masked =  r_masked.to(device,dtype=torch.float32)\n",
    "\n",
    "        optimiser_gen.zero_grad()\n",
    "\n",
    "        #generate the random gender vector\n",
    "        gen_secret = Variable(torch.LongTensor(np.random.choice([1.0], x.shape[0])))#.to(device)\n",
    "        gen_secret = gen_secret * np.random.normal(0.5, math.sqrt(0.01))\n",
    "\n",
    "        gen_secret = gen_secret.type(torch.float32)\n",
    "        #gen_secret =  gen_secret.to(device=device)\n",
    "\n",
    "        # ----------- Generator --------------\n",
    "\n",
    "        #get outputs of the networks\n",
    "        gen_results = generator(x)\n",
    "\n",
    "        pred_secret = disciminator(gen_results)\n",
    "\n",
    "        # 'MSE','MSE_R'\n",
    "        if loss_type == 'MSE':\n",
    "            generator_distortion_loss = distortion_loss(gen_results, x)#.to(device)\n",
    "\n",
    "        elif loss_type == 'MSE_R':\n",
    "            generator_distortion_loss = distortion_loss(gen_results * r_masked, x * r_masked) + distortion_loss(gen_results * non_r_masked, x * non_r_masked)* multiplicator\n",
    "\n",
    "        \n",
    "        G_distortion_loss_accum += generator_distortion_loss.item()\n",
    "\n",
    "        generator_adversary_loss = adversarial_loss(pred_secret, gen_secret)#.to(device)\n",
    "\n",
    "        G_adversary_loss_accum += generator_adversary_loss.item()\n",
    "\n",
    "        generator_loss = generator_distortion_loss + generator_adversary_loss * utility_budget\n",
    "\n",
    "        acc_distortion_loss.append(generator_distortion_loss.item())\n",
    "        acc_gender_loss.append(generator_adversary_loss.item())\n",
    "        acc_generator_loss.append(generator_loss.item())\n",
    "\n",
    "        generator_loss.backward()\n",
    "        optimiser_gen.step()\n",
    "\n",
    "        # ----------- Discriminator --------------\n",
    "\n",
    "        optimiser_discr.zero_grad()\n",
    "\n",
    "        real_pred_secret = disciminator(x)\n",
    "        fake_pred_secret = pred_secret.detach()\n",
    "\n",
    "        acc_true_acc.append(np.mean(torch.sigmoid(real_pred_secret).reshape(-1).clone().detach().cpu().numpy().round() == gender.detach().cpu().numpy()))\n",
    "        acc_fake_acc.append(np.mean(torch.sigmoid(pred_secret).reshape(-1).clone().detach().cpu().numpy().round() == gender.detach().cpu().numpy()))\n",
    "\n",
    "        D_real_loss = adversarial_loss_rf(real_pred_secret, gender)#.to(device)\n",
    "        D_genderless_loss = adversarial_loss_rf(fake_pred_secret, gen_secret)#.to(device)\n",
    "\n",
    "        D_real_loss_accum += D_real_loss.item()\n",
    "        D_fake_loss_accum += D_genderless_loss.item()\n",
    "\n",
    "        discriminator_loss = D_real_loss + D_genderless_loss \n",
    "\n",
    "        acc_genderless_loss.append(D_genderless_loss.item())\n",
    "        acc_true_data_loss.append(D_real_loss.item())\n",
    "        acc_dicriminator_loss.append(discriminator_loss.item())\n",
    "\n",
    "        discriminator_loss.backward()\n",
    "        optimiser_discr.step()\n",
    "\n",
    "    list_fake_acc.append(mean(acc_fake_acc))\n",
    "    list_true_acc.append(mean(acc_true_acc))\n",
    "    list_generator_loss.append(mean(acc_generator_loss))\n",
    "    list_distortion_loss.append(mean(acc_distortion_loss))\n",
    "    list_gender_loss.append(mean(acc_gender_loss))\n",
    "    list_genderless_loss.append(mean(acc_genderless_loss))\n",
    "    list_true_data_loss.append(mean(acc_true_data_loss))\n",
    "    list_dicriminator_loss.append(mean(acc_dicriminator_loss))\n",
    "\n",
    "    print(\"==============================\")\n",
    "    print(\"epoch {}\".format(epochs))\n",
    "\n",
    "    print(\"list_fake_acc {}\".format(mean(acc_fake_acc)))\n",
    "    print(\"list_true_acc {}\".format(mean(acc_true_acc)))\n",
    "    print(\"diff acc {}\".format(mean(acc_true_acc) - mean(acc_fake_acc)))\n",
    "\n",
    "    print(\"list_generator_loss {}\".format(mean(acc_generator_loss)))\n",
    "    print(\"list_distortion_loss {}\".format(mean(acc_distortion_loss)))\n",
    "    print(\"list_gender_loss {}\".format(mean(acc_gender_loss)))\n",
    "    print(\"list_genderless_loss {}\".format(mean(acc_genderless_loss)))\n",
    "    print(\"list_true_data_loss {}\".format(mean(acc_true_data_loss)))\n",
    "    print(\"list_dicriminator_loss {}\".format(mean(acc_dicriminator_loss)))\n",
    "    print(\"==============================\")\n",
    "\n",
    "    if epochs%save_every == 0:\n",
    "        torch.save(disciminator.state_dict(), os.path.join(out_path,'disciminator_{}_final.pth'.format(epochs)))\n",
    "        torch.save(generator.state_dict(), os.path.join(out_path,'generator_{}_final.pth'.format(epochs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211fac1-e2fc-43a6-bdfc-9bf94711db31",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "So far, attempts to use the transformed data on the model has not resulted in success. Presently, I am debugging to determine whether the issue lies within the model itself or data needing further transformation before being sent the Generator. The error relating to my data shape mismatch is logged above in the error text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6e8282c-9517-45e9-8b55-9d8b8ed6cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACCURACY METRICS ??? ANALYSIS FOLDER ##\n",
    "\n",
    "# Implement once working\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb5210a-19a4-4997-9b8c-26f99c0a6330",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "The repository for PrivECG contains a folder named \"analysis\" which provides various python packages which can be utilized for measuring and analyzing the model. Once the model is working properly and I am able to successfully run on all epochs, I plan to import and utilize the analysis packages to preserve the metrics used in the original paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7eeae2fa-7c4d-4077-be2e-eac7bf19e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PUT GRAPHS HERE? ##\n",
    "\n",
    "# from analyse_output import *\n",
    "# from analyse_output_utils import *\n",
    "# from evaluate_privacy import *\n",
    "# from predict_diseases import *\n",
    "# from resnet1d import *\n",
    "# from siamese_train import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0714a19-2513-4584-b7fe-7bbae6479c7f",
   "metadata": {},
   "source": [
    "# Plans\n",
    "\n",
    "While the progress made so far may not seem significant, the paper itself is not too far away from achieving definitive result. With some further debugging of the model and determining changes without hurting performance, it will be determined whether or not the paper is replicatable. So far, the greatest achievement has been formatting the data such that it fits the requested paramterization of the PrivECG model despite coming from a completely separate source. Going forward, the aim is to achieve:\n",
    "\n",
    "- Debugging of the GAN model to determine usability with dataset. With some further exploration, it should be able to be mae to work.\n",
    "- Implement analysis methods used in the original PrivECG paper to measure the results with the new dataset.\n",
    "- Display data in a graphical format to compare to the original figures from the PrivECG paper.\n",
    "- Perform further ablations, determining if it is possible to induce privacy by varying the rhythm pattern. We do have rhythm data provided from the dataset utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da760d4-e1b3-4ff3-8244-191083574dac",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1.  Nolin-Lapalme, A., Avram, R. & Julie, H. (2023). PrivECG: generating private ECG for end-to-end anonymization. Proceedings of the 8th Machine Learning for Healthcare Conference, in Proceedings of Machine Learning Research 219:509-528 Available from https://proceedings.mlr.press/v219/nolin-lapalme23a.html\n",
    "\n",
    "2.  Nolin-Lapalme, A., et al. (2023). privECG. GitHub. [https://github.com/anolinlapalme/privECG](https://github.com/anolinlapalme/privECG)\n",
    "\n",
    "3.\tZheng, Jianwei; Rakovski, Cyril; Danioko, Sidy; Zhang, Jianming; Yao, Hai; Hangyuan, Guo (2019). A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. figshare. Collection. https://doi.org/10.6084/m9.figshare.c.4560497\n",
    "\n",
    "4.\tZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\n",
    "\n",
    "5.\tWeimann, K., Conrad, T.O.F. Transfer learning for ECG classification. Sci Rep 11, 5251 (2021). https://doi.org/10.1038/s41598-021-84374-8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e7e70-5f57-468e-b395-495b3482e5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0b203-5bc1-4d4c-915f-76b605c63316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
